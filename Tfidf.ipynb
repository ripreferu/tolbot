{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du corpus\n",
    "Le corpus est une collection de livres/Bande dessinés pour enfants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Martine à la plage', 'Martine en vacances', 'Martine en confinement', 'Martine chez ses amis', 'Martine à la décharge', 'Martine fait trempette', 'Martine et les chiens', 'Martine a peur', 'Martine à la ferme', \"Luky Luke chez les Chti's\", 'Luky Lucke et Ma Dalton', \"Luky Luke et la Ruée vers l'or\"]\n"
     ]
    }
   ],
   "source": [
    "corpus=[\"Martine à la plage\", \"Martine en vacances\",\"Martine en confinement\",\"Martine chez ses amis\",\"Martine à la décharge\",\"Martine fait trempette\", \"Martine et les chiens\", \"Martine a peur\",\"Martine à la ferme\",\"Luky Luke chez les Chti's\",\"Luky Lucke et Ma Dalton\",\"Luky Luke et la Ruée vers l'or\"]\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création de la matrice Tfidf\n",
    "On va creer la matrice tfidf du corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amis',\n",
       " 'chez',\n",
       " 'chiens',\n",
       " 'chti',\n",
       " 'confinement',\n",
       " 'dalton',\n",
       " 'décharge',\n",
       " 'en',\n",
       " 'et',\n",
       " 'fait',\n",
       " 'ferme',\n",
       " 'la',\n",
       " 'les',\n",
       " 'lucke',\n",
       " 'luke',\n",
       " 'luky',\n",
       " 'ma',\n",
       " 'martine',\n",
       " 'or',\n",
       " 'peur',\n",
       " 'plage',\n",
       " 'ruée',\n",
       " 'ses',\n",
       " 'trempette',\n",
       " 'vacances',\n",
       " 'vers']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer= TfidfVectorizer() # on laisse les options par défauts\n",
    "# on va faire simple\n",
    "matrice_tfidf=vectorizer.fit_transform(corpus)\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais que se passe t'il concrètement ?\n",
    "Le texte subit d'abord un preprocessing puis une tokenization.\n",
    "Grace à l'API de sklearn on peut récupérer ces 2 fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'toto fait de la cuisine'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor=vectorizer.build_preprocessor()\n",
    "tokenizer=vectorizer.build_tokenizer()\n",
    "test_preprocess=preprocessor(\"Toto fait de la cuisine\")\n",
    "test_preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le preprocessing remet le texte en minuscule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['toto', 'fait', 'de', 'la', 'cuisine']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('toto fait de la cuisine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le tokenizer découpe le texte en token ou jeton en français\n",
    "Ces jetons sont stockés dans le vocabulaire.\n",
    "Pour obtenir la matrice tfdif on décompose le texte en \"sac de mot\", on projète les mots sur le vocabulaire.\n",
    "\n",
    "Prenons pour exemple le document 'Martine va la plage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amis</th>\n",
       "      <th>chez</th>\n",
       "      <th>chiens</th>\n",
       "      <th>chti</th>\n",
       "      <th>confinement</th>\n",
       "      <th>dalton</th>\n",
       "      <th>décharge</th>\n",
       "      <th>en</th>\n",
       "      <th>et</th>\n",
       "      <th>fait</th>\n",
       "      <th>...</th>\n",
       "      <th>ma</th>\n",
       "      <th>martine</th>\n",
       "      <th>or</th>\n",
       "      <th>peur</th>\n",
       "      <th>plage</th>\n",
       "      <th>ruée</th>\n",
       "      <th>ses</th>\n",
       "      <th>trempette</th>\n",
       "      <th>vacances</th>\n",
       "      <th>vers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.341494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.776877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   amis  chez  chiens  chti  confinement  dalton  décharge   en   et  fait  \\\n",
       "0   0.0   0.0     0.0   0.0          0.0     0.0       0.0  0.0  0.0   0.0   \n",
       "\n",
       "   ...   ma   martine   or  peur     plage  ruée  ses  trempette  vacances  \\\n",
       "0  ...  0.0  0.341494  0.0   0.0  0.776877   0.0  0.0        0.0       0.0   \n",
       "\n",
       "   vers  \n",
       "0   0.0  \n",
       "\n",
       "[1 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "vecteur=vectorizer.transform(['martine va à la plage'])\n",
    "df=pd.DataFrame(vecteur.toarray(),columns=vectorizer.get_feature_names())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comment exploiter la matrice Tfidf dans le cadre de la recherche d'information\n",
    "L'utilisateur formule une requête. Cette requête est tokenizé puis projeter sur le corpus.\n",
    "En considérant les documents du corpus et la requête comme des vecteurs (Dont les coordonnées serait les coefficients de la matrice), on peut calculer le cosinus de l'angle entre les documents du corpus et la requête.\n",
    "Le document recherché est celui qui possède le plus grand cosinus est le plus grand (c'est à dire une angle petit entre le document et la requête)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def requete(string):\n",
    "    req=vectorizer.transform([string])\n",
    "    req=req.transpose()\n",
    "    long_r=req.shape[0]\n",
    "    resultat=[]\n",
    "    for indice,value in enumerate(corpus):\n",
    "        cosinus= (matrice_tfidf.getrow(indice) @ req) # le cosinus est le produit scalaire divisé par le produit des normes\n",
    "        resultat.append((indice,cosinus)) # ici sci-kit se charge de renormaliser les vecteurs pour nous\n",
    "    resultat.sort(key=lambda item:item[1],reverse=True)\n",
    "    indice,score=resultat[0]\n",
    "    return(corpus[indice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Martine à la plage', 'Luky Lucke et Ma Dalton')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requete(\"Martine plage\"), requete('Lucky Luke Dalton')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Martine en vacances', \"Luky Luke chez les Chti's\")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requete(\"Martine en vacances à la plage\"),requete(\"Martine chez les Chti\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
